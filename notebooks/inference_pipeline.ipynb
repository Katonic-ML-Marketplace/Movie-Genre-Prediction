{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": [
     "imports"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -cikit-learn (/opt/conda/lib/python3.8/site-packages)\n",
      "WARNING: Ignoring invalid distribution -cikit-learn (/opt/conda/lib/python3.8/site-packages)\n",
      "WARNING: Ignoring invalid distribution -cikit-learn (/opt/conda/lib/python3.8/site-packages)\n",
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "WARNING: Ignoring invalid distribution -cikit-learn (/opt/conda/lib/python3.8/site-packages)\n",
      "WARNING: Ignoring invalid distribution -cikit-learn (/opt/conda/lib/python3.8/site-packages)\n",
      "WARNING: Ignoring invalid distribution -cikit-learn (/opt/conda/lib/python3.8/site-packages)\n",
      "WARNING: Ignoring invalid distribution -cikit-learn (/opt/conda/lib/python3.8/site-packages)\n",
      "WARNING: Ignoring invalid distribution -cikit-learn (/opt/conda/lib/python3.8/site-packages)\n",
      "    WARNING: Ignoring invalid distribution -cikit-learn (/opt/conda/lib/python3.8/site-packages)\n",
      "WARNING: Ignoring invalid distribution -cikit-learn (/opt/conda/lib/python3.8/site-packages)\n",
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "WARNING: Ignoring invalid distribution -cikit-learn (/opt/conda/lib/python3.8/site-packages)\n",
      "WARNING: Ignoring invalid distribution -cikit-learn (/opt/conda/lib/python3.8/site-packages)\n",
      "WARNING: Ignoring invalid distribution -cikit-learn (/opt/conda/lib/python3.8/site-packages)\n",
      "WARNING: Ignoring invalid distribution -cikit-learn (/opt/conda/lib/python3.8/site-packages)\n",
      "WARNING: Ignoring invalid distribution -cikit-learn (/opt/conda/lib/python3.8/site-packages)\n",
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "WARNING: Ignoring invalid distribution -cikit-learn (/opt/conda/lib/python3.8/site-packages)\n",
      "WARNING: Ignoring invalid distribution -cikit-learn (/opt/conda/lib/python3.8/site-packages)\n"
     ]
    }
   ],
   "source": [
    "# Installing the Required Libraries for the Notebook\n",
    "\n",
    "import os\n",
    "\n",
    "os.system(\"python -m pip install --upgrade pip -q\")\n",
    "os.system(\"pip install /kfs_private/movie_genre/katonic-1.0-py3-none-any.whl neattext tmdbsimple -q\")\n",
    "os.system(\"pip install scikit-learn==0.24.2 -q\")\n",
    "\n",
    "import tmdbsimple as tmdb\n",
    "import time\n",
    "import urllib\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from joblib import load\n",
    "\n",
    "import neattext as nt\n",
    "import neattext.functions as nfx\n",
    "\n",
    "from katonic.ml.client import MLClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "functions"
    ]
   },
   "outputs": [],
   "source": [
    "# remove some punctuation\n",
    "\n",
    "def remove_punctuation(input_string):\n",
    "    input_string = input_string.replace(',','')\n",
    "    cleaned_string = input_string.replace('.','')    \n",
    "    return cleaned_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.environ[\"TMDB_API_KEY\"] = \"923a3621a665ddd778698f7e578a0490\"\n",
    "api_key = os.environ[\"TMDB_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "pipeline-parameters"
    ]
   },
   "outputs": [],
   "source": [
    "location = 's3://models/2/69a282d78a194fc19e08d14fad354f0f/artifacts/movie_genre_testcase_2_decision_tree_classifier'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "block:scraping_the_data"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting pulling movies from TMDB from each genre. This will take a while, please wait...\n",
      "\t\tThe Dark Knight Rises\n",
      "\t\tMortal Kombat Legends: Battle of the Realms\n",
      "\t\tAmerican Badger\n",
      "\t\tMissing Link\n",
      "\t\tCheckered Ninja\n",
      "\t\tSpies in Disguise\n",
      "\t\tAntz\n",
      "\t\tThe Adventures of Tintin\n",
      "\t\tOver the Hedge\n",
      "\t\tComing to America\n",
      "\t\tThe House with a Clock in Its Walls\n",
      "\t\tMom and Dad\n",
      "\t\tThey Call Me Jeeg\n",
      "\t\tLife of Crime\n",
      "\t\tGreen Room\n",
      "\t\tWeiner\n",
      "\t\tHoly Hell\n",
      "\t\tLo and Behold: Reveries of the Connected World\n",
      "\t\tWe Are Your Friends\n",
      "\t\tThe Judge\n",
      "\t\tIn the Heart of the Sea\n",
      "\t\tThe Adventurer: The Curse of the Midas Box\n",
      "\t\tMinuscule: Valley of the Lost Ants\n",
      "\t\tMuppets Most Wanted\n",
      "\t\tThe Rescuers\n",
      "\t\tSnow White: A Tale of Terror\n",
      "\t\tThe House of Magic\n",
      "\t\tDay of the Siege\n",
      "\t\tLady Gaga: On the Edge\n",
      "\t\tThe Cup\n",
      "\t\tEraserhead\n",
      "\t\tGuilty of Romance\n",
      "\t\tPhenomena\n",
      "\t\tGenius Within: The Inner Life of Glenn Gould\n",
      "\t\tBeirut - Cheap Magic Inside\n",
      "\t\tObituary: Live Xecution\n",
      "\t\tPontypool\n",
      "\t\tA Shot in the Dark\n",
      "\t\tThe Conversation\n",
      "\t\t27 Dresses\n",
      "\t\tThe Duchess\n",
      "\t\tLook Who's Talking Too\n",
      "\t\tMy Super Ex-Girlfriend\n",
      "\t\tBattlestar Galactica: Razor\n",
      "\t\tThe Last Mimzy\n",
      "\t\tThe Christmas Card\n",
      "\t\tVampire Bats\n",
      "\t\tThe V Word\n",
      "\t\tPrimer\n",
      "\t\tRed Eye\n",
      "\t\tMarathon Man\n",
      "\t\tCompany K\n",
      "\t\tGoing Back\n",
      "\t\tSilence of the Sea\n",
      "\t\tTime Machine: When Cowboys Were King\n",
      "\t\tSe buscan II, el tesoro de la hacienda\n",
      "\t\tA Pioneer Miracle\n",
      "\tPulled movies for genres - 28,12,16,35,80,99,18,10751,14,36,27,10402,9648,10749,878,10770,53,10752,37\n",
      "\n",
      "\n",
      "Originally we had  1868  movies\n",
      "After removing duplicates we have  1715  movies\n",
      "Done! Created a dataset where each movie must have an associated overview.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Syncing tmdb.API_KEY with Our Own api_key & Initiating a search \n",
    "\n",
    "tmdb.API_KEY = api_key\n",
    "# Extracting the Genre IDs and Genre Names that are available in TMDB Database.\n",
    "\n",
    "Genre_dict = tmdb.Genres().movie_list()[\"genres\"]\n",
    "\n",
    "# Mapping Genre IDs with Genre Names and making them a Dictionary.\n",
    "\n",
    "Genres_id_name_dict = dict(zip([ movie[\"id\"] for movie in Genre_dict], [ movie[\"name\"] for movie in Genre_dict]))\n",
    "\n",
    "# Let's separate out the IDs only.\n",
    "\n",
    "genre_ids = list(Genres_id_name_dict.keys())\n",
    "\n",
    "# By using the Above Ids we'll scrape the data from themoviedb.org for the base year of 2017.\n",
    "\n",
    "movies = []\n",
    "baseyear = 2022\n",
    " \n",
    "print('Starting pulling movies from TMDB from each genre. This will take a while, please wait...')\n",
    "done_ids=[]\n",
    "for g_id in genre_ids:\n",
    "    baseyear -= 1\n",
    "    for page in range(1,6,1): # (1,6,1)\n",
    "        time.sleep(1)\n",
    "    \n",
    "        url = 'https://api.themoviedb.org/3/discover/movie?api_key=' + api_key\n",
    "        url += '&language=en-US&sort_by=popularity.desc&year=' + str(baseyear) \n",
    "        url += '&with_genres=' + str(g_id) + '&page=' + str(page)\n",
    " \n",
    "        data = urllib.request.urlopen(url).read()\n",
    " \n",
    "        dataDict = json.loads(data)\n",
    "        movies.extend(dataDict[\"results\"])\n",
    "    last_movies = list(map(lambda x: x['title'],movies[-3:]))\n",
    "    for title in last_movies:\n",
    "        print('\\t\\t'+title)\n",
    "    done_ids.append(str(g_id))\n",
    "print(\"\\tPulled movies for genres - \"+','.join(done_ids))\n",
    "print('\\n')\n",
    " \n",
    "# Remove duplicates movies if any Present in the Above movies.\n",
    "\n",
    "movie_ids = [m['id'] for m in movies]\n",
    "print (\"Originally we had \",len(movie_ids),\" movies\")\n",
    "movie_ids=np.unique(movie_ids)\n",
    "seen_before=[]\n",
    "no_duplicate_movies=[]\n",
    "for i in range(len(movies)):\n",
    "    movie=movies[i]\n",
    "    if movie[\"overview\"]:\n",
    "        movie_id=movie['id']\n",
    "        if movie_id in seen_before:\n",
    "            continue\n",
    "            print (\"Seen before\")\n",
    "        else:\n",
    "            seen_before.append(movie_id)\n",
    "        no_duplicate_movies.append(movie)\n",
    "print (\"After removing duplicates we have \",len(no_duplicate_movies), \" movies\")\n",
    "\n",
    "# Picking the movies which must have associated an overview.\n",
    "\n",
    "movie_titles = []\n",
    "movies_with_overviews=[] \n",
    "for i in range(len(no_duplicate_movies)):\n",
    "    movie=no_duplicate_movies[i]\n",
    "    overview=movie['overview']\n",
    "    \n",
    "    if len(overview)==0:\n",
    "        continue\n",
    "    else:\n",
    "        movies_with_overviews.append(movie)\n",
    "        movie_titles.append(movie['original_title'])\n",
    "\n",
    "print(\"Done! Created a dataset where each movie must have an associated overview.\\n\")\n",
    "\n",
    "# Making a DataFrame with the above text content and Target columns.\n",
    "\n",
    "content = [movie[\"overview\"] for movie in movies_with_overviews]\n",
    "\n",
    "final_data = pd.DataFrame(content,columns=[\"overview\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": [
     "block:loading_transformers"
    ]
   },
   "outputs": [],
   "source": [
    "# Loading all the Transformers.\n",
    "\n",
    "count_vectorizer = load(\"/kfs_private/movie_genre/CountVectorizer.joblib\")\n",
    "\n",
    "tf_idf_transformer = load(\"/kfs_private/movie_genre/TFIDF_transformer.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": [
     "block:loading_best_model"
    ]
   },
   "outputs": [],
   "source": [
    "# Loading the Best model for the Inference.\n",
    "\n",
    "mlc = MLClient(exp_name=\"movie_genre_testcase\")\n",
    "\n",
    "model_ml = mlc.load_model(location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": [
     "block:transforming_data",
     "prev:scraping_the_data",
     "prev:loading_transformers"
    ]
   },
   "outputs": [],
   "source": [
    "final_data[\"overview\"] = final_data[\"overview\"].apply(lambda x: remove_punctuation(x)) \n",
    "# Removing Stopwords from Overviews.\n",
    "final_data[\"overview\"] = final_data[\"overview\"].apply(nfx.remove_stopwords)\n",
    "\n",
    "X=count_vectorizer.transform(final_data[\"overview\"]).toarray()\n",
    "\n",
    "X_tfidf = tf_idf_transformer.transform(X).toarray()\n",
    "\n",
    "X_train = pd.DataFrame(X_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": [
     "block:inference_prediction",
     "prev:transforming_data",
     "prev:loading_best_model"
    ]
   },
   "outputs": [],
   "source": [
    "predictions = model_ml.predict(X_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mlb' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2201/4077616684.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmlb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'mlb' is not defined"
     ]
    }
   ],
   "source": [
    "pd.DataFrame(predictions, columns = mlb.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictionsnb=[]\n",
    "for i in range(X_test_tfidf.shape[0]):\n",
    "    pred_genres=[]\n",
    "    movie_label_scores=predsnb[i]\n",
    "    for j in range(len(movie_label_scores)):\n",
    "        #print j\n",
    "        if movie_label_scores[j]!=0:\n",
    "            genre=Genre_ID_to_name[genre_list[j]]\n",
    "            pred_genres.append(genre)\n",
    "    predictionsnb.append(pred_genres)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "kubeflow_notebook": {
   "autosnapshot": false,
   "docker_image": "katonic/usecaseb1:4.0",
   "experiment": {
    "id": "new",
    "name": "movie-genre"
   },
   "experiment_name": "movie-genre",
   "katib_metadata": {
    "algorithm": {
     "algorithmName": "grid"
    },
    "maxFailedTrialCount": 3,
    "maxTrialCount": 12,
    "objective": {
     "objectiveMetricName": "",
     "type": "minimize"
    },
    "parallelTrialCount": 3,
    "parameters": []
   },
   "katib_run": false,
   "pipeline_description": "movie-genre model inference",
   "pipeline_name": "movie-genre-inference",
   "snapshot_volumes": false,
   "steps_defaults": [],
   "storage_class_name": "default",
   "volume_access_mode": "rwo",
   "volumes": [
    {
     "annotations": [],
     "mount_point": "/kfs_private",
     "name": "private-storage-9bc0",
     "size": 1,
     "size_type": "Gi",
     "snapshot": false,
     "snapshot_name": "",
     "type": "pvc"
    }
   ]
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
